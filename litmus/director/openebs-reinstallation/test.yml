---
- hosts: localhost
  connection: local

  vars_files:
    - test_vars.yml

  tasks:

    - block: 
      
        ## Generating the testname for deployment
        - include_tasks: /ansible-utils/create_testname.yml

        ## Record Start-Of-Test In Litmus Result CR
        - include_tasks: /ansible-utils/update_litmus_result_resource.yml
          vars:
            status: 'SOT'
          
        ## Saving the director url
        - set_fact:
            director_url : "http://{{ director_ip }}:30380"
        
        ## Getting username
        - name: Get username
          shell: cat /etc/secret-volume/username
          register: username

        ## Getting password     
        - name: Get password
          shell: cat /etc/secret-volume/password
          register: password

        ## Fetch the projectid of the project where the cluster is running
        - name: Fetch the projectid of the project where the cluster is running
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/project"
            method: GET
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            status_code: 200
          register: project_details

        ## Saving Project id
        - name: Saving project id
          set_fact:
            project_id: "{{ project_details.json.data[0].id }}"

        ## Getting node details of the cluster
        ## Selecting the node which is in active state in the cluster
        - name: Getting the node details of the cluster which is in active state
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/nodes?state=active&clusterId={{ cluster_id }}"
            method: GET
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            body_format: json
            status_code: 200
          register: node_cluster

        ## Define variable node_id
        - set_fact:
            node_id: []

        ## Storing the id of the nodes in the cluster
        - name: Storing the id of nodes in the cluster
          set_fact:
            node_id: "{{ node_id  + [item.id] }}"
          loop: "{{ node_cluster.json.data }}"

        ## Fail the test if it contains less than two nodes
        ## Minimum two nodes required
        - name: Checking if the cluster contains atleast two nodes
          fail:
            msg: Minimum two nodes are required for the test
          when: "{{ node_id | length }} < 2"

        ## Labeling node-1 of the Cluster with controlPlaneNode=true and dataPlaneNode=flase
        ## With the first element in the node_id list
        - name: Labeling node-1 of the cluster
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/nodes/{{ node_id[0] }}/?action=labelnodes"
            method: POST
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            status_code: 202
            body_format: json
            body: '{"controlPlaneNode": true, "dataPlaneNode": flase }'
          register: labelnode1

        ## Labeling node-2 of the Cluster with controlPlaneNode=false and dataPlaneNode=true
        ## With the second element in the node_id list
        - name: Labeling node-2 of the cluster
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/nodes/{{ node_id[1] }}/?action=labelnodes"
            method: POST
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            body_format: json
            status_code: 202
            body: '{"controlPlaneNode": false, "dataPlaneNode": true }'
          register: labelnode2

        ## Creating openebs
        ## Also accepting 405 error code for openebs is already installed
        - name: Giving required variables for openebs installation
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/clusters/{{ cluster_id }}/openebses"
            method: POST
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            body_format: json
            body: '{ "clusterId": "{{ cluster_id }}","creatorId": "{{ group_id }}","projectId": "{{ project_id }}","templateId": "{{ template_id }}","namespace": "{{ namespace }}","defaultDirectory": "{{ default_directory }}","dockerRegistry": "{{ docker_registry }}","includeDeviceFilters": "{{ include_device_filters }}","excludeDeviceFilters": "{{ exclude_device_filters }}","cpuResourceLimit": "{{ cpu_resource_limit }}","memoryResourceLimit": " {{ memory_resource_limit }}","installationMode": "{{ installation_mode }}" }'         
            status_code: 201,405
          register: get_openebs

        ## Check if openebs is already installed
        - name: Checking if openebs is already installed or not
          fail: 
            msg: OpenEBS is Already  installed in your cluster. If you still want to install then please remove the older one and try again.
          when: "{{ get_openebs.status }} == '405'"

        ## If it still not fail then the status code we received is 201 and not 405
        ## Then we should install the openebs in the cluster and agin test
        ## After installing the next time it should give status code 405
        - name: Getting the installation Manifest for openebs installation
          set_fact:
            installopenebs: "{{ get_openebs.json.installationManifest }}"

        - name: Getting the id
          set_fact:
            openebsid: "{{ get_openebs.json.id }}"

        ## Checking the id
        - name: Getting into the openebs installtion stage and checking the id
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/openebses/{{ openebsid }}"
            method: GET
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            body_format: json
            status_code: 200
          register: install_openebs

        # Installing openebs on the external cluster with labeled control plane components
        - name: Installing openebs on the external cluster with control plane components at node-1 only
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/openebses/{{ openebsid }}/?action=openebsinstall"
            method: POST
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            body_format: json
            body: "{{ installopenebs }}"
            status_code: 200
          register: res_openebs


        ## Getting openebs job id
        - name: Getting openebs job id
          set_fact: 
            openebs_job_id: "{{ res_openebs.json.id }}"

        ## Getting into the openebsjob
        - name: Getting into openebs job
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/openebsjobs/{{ openebs_job_id }}"
            method: GET
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            body_format: json
            status_code: 200
          register: openebs_job
          until: openebs_job.json.jobStatus.phase is defined and openebs_job.json.jobStatus.phase == "Online"
          delay: 5
          retries: 20 

        ## Creating openebs again (reinstallation)
        - name: Creating openebs again (reinstallation)
          uri:
            url: "{{ director_url }}/v3/groups/{{ group_id }}/clusters/{{ cluster_id }}/openebses"
            method: POST
            url_username: "{{ username.stdout }}"
            url_password: "{{ password.stdout }}"
            force_basic_auth: yes
            return_content: yes
            body_format: json
            body: '{ "clusterId": "{{ cluster_id }}","creatorId": "{{ group_id }}","projectId": "{{ project_id }}","templateId": "{{ template_id }}","namespace": "{{ namespace }}","defaultDirectory": "{{ default_directory }}","dockerRegistry": "{{ docker_registry }}","includeDeviceFilters": "{{ include_device_filters }}","excludeDeviceFilters": "{{ exclude_device_filters }}","cpuResourceLimit": "{{ cpu_resource_limit }}","memoryResourceLimit": " {{ memory_resource_limit }}","installationMode": "{{ installation_mode }}" }'         
            status_code: 405
          register: get_openebs_again

        - set_fact:
            flag: "Pass"

      rescue:
        - name: Setting fail flag
          set_fact:
            flag: "Fail"

      always:
        ## RECORD END-OF-TEST IN LITMUS RESULT CR
        - include_tasks: /ansible-utils/update_litmus_result_resource.yml
          vars:
            status: 'EOT'
            